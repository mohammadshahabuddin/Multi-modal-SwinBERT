# Multi-modal-SwinBERT
In this project, we have proposed a Multi-modal video captioning model based on SwinBERT. We have used Video frames and Audio together to get video captions from videos.

Our code is based on SwinBERT mentioned in https://github.com/microsoft/SwinBERT. Please follow the steps mentioned in this link to download pretrained Video Swin Transformers. We have also followed the data structure of SwinBERT. 

You can generate mel-spectrogram from the videos using this colab notebook:https://colab.research.google.com/drive/1ngaHaEjiufVIdSQfXraMLmjXeC_KnRVH?usp=sharing

You can download the dataset used in experiments from here and place in datasets folder:
Link1 (Total 35 videos):
https://drive.google.com/file/d/1ew8WeZ18RBFMnrMI2IG1EtvcLWCi14wz/view?usp=sharing
Link2 ( Total 115 videos):
https://drive.google.com/file/d/18W-7EklFXOzeVchz_WnkSoJX1I7J44Db/view?usp=sharing
